<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Heap fragmentation or how my micro-benchmark went wrong</title>
  <meta name="description" content="Micro-benchmarking code always looks simple: a few variables, a small for loop and two std::chrono calls. I think this simplicity is an illusion.Micro-benchmarking is either complicated or inaccura..." />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="Thoughts from a Wall Street developer" />
  <meta property="og:title" content="Heap fragmentation or how my micro-benchmark went wrong"/>
  
  <meta property="og:description" content="Micro-benchmarking code always looks simple: a few variables, a small for loop and two std::chrono calls. I think this simplicity is an illusion.Micro-benchmarking is either complicated or inaccura..." />
  
  <meta property="og:image" content="http://david-grs.github.io" />
  <meta property="og:url" content="http://david-grs.github.io/heap_fragmentation_micro_benchmark" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2016-12-19T21:56:00+01:00">

  <link rel="canonical" href="http://david-grs.github.io/heap_fragmentation_micro_benchmark"/>
  <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />

  <link rel="apple-touch-icon" sizes="57x57" href="/assets/favicon/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/favicon/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/favicon/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/favicon/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/favicon/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/favicon/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/favicon/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/favicon/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/assets/favicon/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/assets/favicon/favicon-194x194.png" sizes="194x194">
  <link rel="icon" type="image/png" href="/assets/favicon/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/assets/favicon/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="/assets/favicon/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="/assets/favicon/manifest.json">
  <link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#00aba9">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#ffffff"> 
  
</head>

  <body itemscope itemtype="http://schema.org/Article">
    <!-- header start -->

<a href="http://david-grs.github.io" class="logo-readium"><span class="logo" style="background-image: url()"></span></a>

<!-- header end -->

    <main class="content" role="main">
      <article class="post">
        
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Heap fragmentation or how my micro-benchmark went wrong</h1>
            <div class="cf post-meta-text">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person">David Gross</h4>
              on
              <time datetime="2016-12-19T21:56:00+01:00">19 Dec 2016</time>
              <!-- , tagged on <span class="post-tag-">, <a href="/tag/"></a></span> -->
            </div>
          </div>
        </div>
        <br>
        <br>
        <br>
        
        <section class="post-content">
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
          <a name="topofpage"></a>
          <p>Micro-benchmarking code always looks simple: a few variables, a small <em>for</em> loop and two <em>std::chrono</em> calls. I think this simplicity is an illusion.
Micro-benchmarking is either complicated or inaccurate. </p>

<p>You have to be careful that the compiler does not optimize out the code you are timing, accurately measure the time and know your time resolution,
all the caches are usually hot (as you loop over the same operation) and you will get a totally different cache hit rate than in production, a “production-like” set of inputs 
has to be generated — without affecting the resuts of the benchmark of course! —, on each iteration of the benchmark 
the state of your object is changing but should still allow the benchmark to continue, etc. It is really hard.</p>

<p>And this is why I usually don’t micro-benchmark: it is too hard for what it is ; you will get numbers and finally be disappointed or puzzled 
because you will not get the same latencies in production.</p>

<p>I prefer measuring the impact of my code changes directly in production — or in a production-like environment. The initial cost of setting up such timing 
system might be higher, but on the long term you get a lot of benefits from it. Lots of code changes can simply not be micro-benchmarked at all. In his 
talk <a href="https://www.youtube.com/watch?v=Qq_WaiwzOtI"><em>Optimization Tips - Mo’ Hustle Mo’ Problems</em></a>, Andrei Alexandrescu is presenting the speed gain of 
not inlining the destructor of an object — by simply defining an empty destructor in the source file instead of the default one. Good luck 
to micro-benchmark that, and if you actually do it <em>somehow</em>, I guess you will get the opposite result, as having the <em>inlined</em> call will save some instructions
and the instruction cache won’t be polluted.</p>

<p>This post is about my last adventure with a micro-benchmark. </p>

<h2 id="the-simplest-micro-benchmark">The simplest µ-benchmark</h2>
<p>This is a very simple — and the most boring I could find — micro-benchmark:</p>
<noscript><pre>void benchmark_unordered_map_emplace()
{
    std::unordered_map&lt;int, int&gt; um;
    
    auto start = std::chrono::system_clock::now();
    for (int i = 0; i &lt; Iterations; ++i)
        um.emplace(i, i);
    auto end = std::chrono::system_clock::now();
    
    std::cout &lt;&lt; Iterations &lt;&lt; &quot; iterations of umap&lt;int, int&gt;::emplace() took &quot; 
              &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(end - start).count() 
              &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=awesome_benchmark.cc"> </script>

<p><br />
This gives us the output: <code>100000 iterations of umap&lt;int, int&gt;::emplace() took 565ms</code>. Awesome. This is exactly what we wanted to know.</p>

<p>A few hours later, we added a lot of other small functions like this one. We are now measuring the time of the <em>emplace</em> operation for different containers,
with different contained type — to change their size and the cost of the move, copy, construction and destruction operations — and with different
number of elements in the container. We even added a layer of template because it looks better!</p>

<p>Our <em>benchmark()</em> function is now something like this:</p>
<noscript><pre>void benchmark()
{
    {
        std::mt19937 gen(seed);
        std::uniform_int_distribution&lt;&gt; rng;
        auto gen = [&amp;]() { return rng(gen); };
        
        benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
        benchmark_emplace&lt;std::map&lt;int, int&gt;&gt;(gen);
        benchmark_emplace&lt;boost::container::flat_map&lt;int, int&gt;&gt;(gen);
    }
  
    {
        // Foo is a medium size object...
        benchmark_emplace&lt;std::unordered_map&lt;Foo, Foo&gt;&gt;(&amp;Foo::Generate);
        benchmark_emplace&lt;std::map&lt;Foo, Foo&gt;&gt;(&amp;Foo::Generate);
        benchmark_emplace&lt;boost::container::flat_map&lt;Foo, Foo&gt;&gt;(&amp;Foo::Generate);

        // We also test big objects, different number of elements, and a lot of other fun stuff. 
    }
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=even_more_awesome_benchmark.cc"> </script>

<p><br /></p>

<h2 id="the-tragedy">The tragedy</h2>
<p><em>At some point</em>, you decide to re-order the function calls. You don’t know why — just for convenience. And boom. You didn’t 
expect <em>anything</em> to change because you have been at staring these numbers for hours… but now you get: </p>

<p><code>100000 iterations of umap&lt;int, int&gt;::emplace() took 1143ms</code></p>

<p>How come? You run again and get the same results. Nothing changed. You checkout the previous commit and test again: it is fixed. How can a simple re-ordering of function
calls change by more than a factor two the time of this <em>for</em> statement?</p>

<p>You decide to run the benchmark twice, as first benchmark and last one:</p>

<noscript><pre>void benchmark()
{
    std::cout &lt;&lt; &quot;first run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
    
    {
        // a lot of other benchmarks (cf previous listing)...;
    }
    
    std::cout &lt;&lt; &quot;second run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=benchmark_cmp.cc"> </script>

<p><br />
and you still get:</p>

<pre><code>first run:   100000 iterations of umap&lt;int, int&gt;::emplace() took 565ms
second run: 100000 iterations of umap&lt;int, int&gt;::emplace() took 1143ms
</code></pre>

<h2 id="hardware-counters-are-your-friends">Hardware counters are your friends</h2>
<p>In this kind of scenario, you have a quite limited set of options. You might think about looking at the disassembly. I know that we all love 
the <a href="http://gcc.godbolt.org">GCC explorer</a>, but when you are benchmarking containers, the assembly code will be very long.</p>

<p>To get more insights, I like using hardware counters. I wrote a while ago a short C++ library, <a href="https://github.com/david-grs/papipp">libpapipp</a>, that records
hardware events, based on the reference C library <a href="http://icl.cs.utk.edu/papi/">libpapi</a>. Let’s use it here to measure the number of instructions and cycles.</p>

<noscript><pre>template &lt;typename Container, typename KeyGenerator&gt;
void benchmark_emplace(KeyGenerator gen)
{
    Container c;
    
     // we measure the hardware events total instructions and total cycles
    papi::event_set&lt;PAPI_TOT_INS, PAPI_TOT_CYC&gt; events;
    
    events.start_counters();
    for (int i = 0; i &lt; Iterations; ++i)
        um.emplace(gen(), {});
    events.stop_counters();
    
    std::cout &lt;&lt; events.at&lt;0&gt;().counter() &lt;&lt; &quot; instructions, &quot; &lt;&lt; events.at&lt;0&gt;().counter() &lt;&lt; &quot; cycles&quot; &lt;&lt; std::endl;
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=benchmark_papipp.cc"> </script>

<p><br />
This allows us to see that the number of instructions executed is ~25% higher in the second run. As our code is identical, it means that <em>more</em> code is executed.</p>

<h2 id="heap-fragmentation">Heap fragmentation</h2>
<p>As you guessed because it is the title of this article, the difference comes from the heap. At the beginning of the micro-benchmark, the heap is in a <em>clean</em> state, while after a lot of 
container operations — insertions and deletions — it is heavily fragmented, and one malloc() call might take much more time than expected. </p>

<p>Let’s confirm that by measuring the time we spend in <em>malloc()</em> and <em>free()</em>. I updated for that an old <a href="https://github.com/david-grs/mtrace">C++ wrapper around the malloc hooks</a> that I developed 
to follow each memory allocation — by printing them. Here we don’t want to print them (there are millions!), but measure the time spent in these functions:</p>

<noscript><pre>template &lt;typename Container, typename KeyGenerator&gt;
void benchmark_emplace(KeyGenerator gen)
{
    Container c;
   
    // this setups our malloc/free/realloc hooks
    mtrace&lt;malloc_chrono&gt; mt;
  
    for (int i = 0; i &lt; Iterations; ++i)
        c.emplace(gen(), {});
    
    std::cout &lt;&lt; &quot;time spent in malloc(): &quot; &lt;&lt; duration_cast&lt;milliseconds&gt;(mt.malloc_time()).count() &lt;&lt; &quot;ms\n&quot;
              &lt;&lt; &quot;time spent in free(): &quot; &lt;&lt; duration_cast&lt;milliseconds&gt;(mt.free_time()).count() &lt;&lt; &quot;ms\n&quot;
              &lt;&lt; &quot;time spent in realloc(): &quot; &lt;&lt; duration_cast&lt;milliseconds&gt;(mt.realloc_time()).count() &lt;&lt; &quot;ms&quot; &lt;&lt; std::endl;
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=benchmark_mtrace.cc"> </script>

<p><br />
… which gives us immediately the answer:</p>

<pre><code>first run: benchmark_unordered_map_emplace() took 565ms
time spent in malloc(): 231ms
time spent in free(): 1ms
time spent in realloc(): 0ms

second run: benchmark_unordered_map_emplace() took 1143ms
time spent in malloc(): 916ms
time spent in free(): 94ms
time spent in realloc(): 0ms
</code></pre>

<p>We were spending almost 90% of the CPU time in <em>malloc()</em> and <em>free()</em> the second run of the benchmark! To get even more in depth, the GNU extension offers  <em>malloc_info</em> that returns
the exhaustive list of bins — chunks that have been freed — by category (size, unsorted, fast). </p>

<pre><code>&lt;malloc version="1"&gt;
&lt;heap nr="0"&gt;
&lt;sizes&gt;
&lt;size from="33" to="48" total="383999952" count="7999999"/&gt;
&lt;size from="49" to="64" total="64" count="1"/&gt;
&lt;size from="33" to="33" total="99" count="3"/&gt;
&lt;unsorted from="145" to="1009" total="1156000346" count="3999994"/&gt;
&lt;/sizes&gt;
&lt;total type="fast" count="8000000" size="384000016"/&gt;
&lt;total type="rest" count="3999997" size="1156000445"/&gt;
</code></pre>

<p>What happened in our case is that the destructors or several big containers just freed millions of chunks of different sizes. Remember that our code:</p>
<noscript><pre>void benchmark()
{
    std::cout &lt;&lt; &quot;first run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
    
    {
        // a lot of other benchmarks (cf previous listing)...
        // several destructors of big containers are called on the next line
    }
    
    std::cout &lt;&lt; &quot;second run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=benchmark_cmp2.cc"> </script>

<p><br />
On the next <em>malloc()</em> call, the several <em>freelists</em> will be merged. If we introduce one small <em>malloc()</em> call before our second run of the benchmark and run <em>malloc_info</em> again, we
now get a heap in a clean state, and the difference of time immediately disappears.</p>

<pre><code>&lt;malloc version="1"&gt;
&lt;heap nr="0"&gt;
&lt;sizes&gt;
&lt;/sizes&gt;
&lt;total type="fast" count="0" size="0"/&gt;
&lt;total type="rest" count="0" size="0"/&gt;
</code></pre>

<p>As a solution, we could simply rearrange our code to not destroy any containers before the end of all benchmarks:</p>
<noscript><pre>void benchmark()
{
    std::cout &lt;&lt; &quot;first run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
    // a lot of other benchmarks (cf previous listing)...
    std::cout &lt;&lt; &quot;second run&quot; &lt;&lt; benchmark_emplace&lt;std::unordered_map&lt;int, int&gt;&gt;(gen);
}</pre></noscript>
<script src="https://gist.github.com/david-grs/38b359aa9f20d7d27444c16c9e411855.js?file=benchmark_cmp3.cc"> </script>

<p><br />
Micro-benchmarking is hard. Be very careful while doing it ; this kind of mistakes or wrong measurements can happen, even if you are using Google Benchmark ;)</p>


        </section>
        <footer class="post-footer">
          <section class="share">
            
              
            
          </section>
        </footer>
        <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>David Gross</h4>
              <p class="bio"></p>
              <hr>
              <p class="published">Published <time datetime="2016-12-19 21:56">19 Dec 2016</time></p>
            </section>
          </div>
          
          <div class="isRight">
            <h5 class="index-headline featured"><span>Supported by</span></h5>
            <footer class="site-footer">
              <section class="poweredby">Proudly published with <a href="http://jekyllrb.com"> Jekyll</a></section>
              <a class="subscribe" href="/feed.xml"> <span class="tooltip"> <i class="fa fa-rss"></i> You should subscribe to my feed.</span></a>
              <div class="inner">
                <section class="copyright">All content copyright <a href="/">David Gross</a> &copy; 2016<br>All rights reserved.</section>
              </div>
            </footer>
          </div>
        </div>
        
        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'david-grs'; // required: replace example with your forum shortname

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        
      </article>
    </main>
    <div class="bottom-closer">
      <div class="background-closer-image"  style="background-image: url(/assets/images/cover.jpg)">
        Image
      </div>
      <div class="inner">
        <h1 class="blog-title">Thoughts from a Wall Street developer</h1>
        <h2 class="blog-description">A blog about C++, with an emphasis on low-latency, performance measurements and system programming.
</h2>
        <a href="/" class="btn">Back to Overview</a>
      </div>
    </div>
    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>


    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75603420-1', 'auto');
  ga('send', 'pageview');

</script>


  </body>
</html>
